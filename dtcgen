#!/usr/bin/python3
import csv

import click
import graphviz
import numpy as np
from nyoka import skl_to_pmml
from sklearn import tree, pipeline, ensemble, model_selection, datasets


@click.group()
@click.option('-d', '--max-depth', default=0, show_default=True, help='Maximum tree depth, 0 for none')
@click.option('-e', '--n-estimators', default=1, show_default=True, help='Number of estimators')
@click.option('-o', '--out-file', default='out.pmml', show_default=True, help='Name of the output file')
@click.option('-t', '--train-size', default=0.8, show_default=True, help='Fraction of the dataset to use for model training')
@click.pass_context
def main(ctx, max_depth, n_estimators, out_file, train_size):
    """Decision tree ensembles generator."""
    ctx.obj['MAX_DEPTH'] = max_depth if max_depth != 0 else None
    ctx.obj['N_ESTIMATORS'] = n_estimators
    ctx.obj['OUT_FILE'] = out_file
    ctx.obj['TRAIN_SIZE'] = train_size


@main.command('random')
@click.option('-c', '--n-classes', type=int, required=True, help='Number of classes')
@click.option('-f', '--n-features', type=int, required=True, help='Number of features')
@click.option('-s', '--n-samples', type=int, required=True, help='Number of samples')
@click.pass_context
def random_command(ctx, n_classes, n_features, n_samples):
    """Generate a random decision tree ensemble."""
    max_depth = ctx.obj['MAX_DEPTH']
    n_estimators = ctx.obj['N_ESTIMATORS']
    out_file = ctx.obj['OUT_FILE']
    train_size = ctx.obj['TRAIN_SIZE']

    X, Y = datasets.make_classification(
        n_samples=n_samples,
        n_features=n_features,
        n_classes=n_classes,
        n_informative=n_features,
        n_repeated=0,
        n_redundant=0,
        n_clusters_per_class=1
    )
    feat_names = [f'feat_{i}' for i in range(n_features)]
    class_names = [f'class_{i}' for i in range(n_classes)]
    Y = [class_names[el] for el in Y]
    Y_one_hot = to_one_hot(Y, class_names)
    X_train, X_test, Y_train, Y_test = train_split(X, Y_one_hot, feat_names, class_names, train_size, out_file)

    Y_train_target = to_target(Y_train, class_names)
    Y_test_target = to_target(Y_test, class_names)
    clf = dtcgen(X_train, Y_train_target, feat_names, class_names, max_depth, n_estimators, out_file)
    print_accuracy(clf, X_test, Y_test_target)


@main.command('csv')
@click.argument('infile', type=click.Path(exists=True, dir_okay=False))
@click.option('-c', '--n-classes', type=int, required=True, help='Number of classes')
@click.pass_context
def csv_command(ctx, n_classes, infile):
    """Generate a decision tree ensemble from CSV data.

    INFILE is the name of the input data."""
    max_depth = ctx.obj['MAX_DEPTH']
    n_estimators = ctx.obj['N_ESTIMATORS']
    out_file = ctx.obj['OUT_FILE']
    train_size = ctx.obj['TRAIN_SIZE']

    X, Y, feat_names, class_names = read_csv(infile, n_classes)
    X_train, X_test, Y_train, Y_test = train_split(X, Y, feat_names, class_names, train_size, out_file, infile)

    Y_train_target = to_target(Y_train, class_names)
    Y_test_target = to_target(Y_test, class_names)
    clf = dtcgen(X_train, Y_train_target, feat_names, class_names, max_depth, n_estimators, out_file)
    print_accuracy(clf, X_test, Y_test_target)


def train_split(X, Y, feat_names, class_names, train_size, out_file, infile=None):
    if train_size < 1.0:
        X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, train_size=train_size)
        XY_train = [np.append(X_train[i], Y_train[i]) for i in range(len(X_train))]
        XY_test = [np.append(X_test[i], Y_test[i]) for i in range(len(X_test))]
        write_csv(XY_train, feat_names, class_names, f'{out_file}_train.csv')
        write_csv(XY_test, feat_names, class_names, f'{out_file}_test.csv')
    else:
        X_train = X
        Y_train = Y
        if infile is not None:
            X_test, Y_test = read_csv(infile.replace('_train.csv', '_test.csv'))
        else:
            X_test = []
            Y_test = []

    return X_train, X_test, Y_train, Y_test


def dtcgen(X_train, Y_train, feat_names, class_names, max_depth, n_estimators, out_file):
    """Generation function for decision tree ensembles."""
    if n_estimators <= 1:
        clf = tree.DecisionTreeClassifier(max_depth=max_depth)
        clf = clf.fit(X_train, Y_train)
        draw_graph(clf, feat_names, class_names, out_file, None)
    else:
        clf = ensemble.RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)
        clf = clf.fit(list(X_train), list(Y_train))

        for i in range(len(clf.estimators_)):
            draw_graph(clf.estimators_[i], feat_names, class_names, out_file, i)

    pipe = pipeline.Pipeline([('clf', clf)])
    skl_to_pmml(pipeline=pipe, col_names=feat_names, pmml_f_name=out_file)

    return clf


def to_target(Y, class_names):
    """Convert classes from one-hot to target column"""
    return [class_names[cl.index('1')] for cl in Y]


def to_one_hot(Y, class_names):
    """Convert classes from target column to one-hot"""
    Y_one_hot = []
    n_classes = len(class_names)
    for el in Y:
        next_el = ['0'] * n_classes
        next_el[class_names.index(el)] = '1'
        Y_one_hot.append(next_el)
    return Y_one_hot


def print_accuracy(clf, X_test, Y_test):
    """Print classifier accuracy."""
    c_ans = 0
    for pred, ans in zip(clf.predict(X_test), Y_test):
        if pred == ans:
            c_ans += 1
    print(f"Classifier accuracy: {c_ans / len(Y_test)}")


def draw_graph(clf, feat_names, class_names, out_file, n):
    """Export graph for classifier."""
    dot_data = tree.export_graphviz(clf, feature_names=feat_names, class_names=class_names, filled=True, rounded=True) 
    graph = graphviz.Source(dot_data)
    filename = f'{out_file}.gv' if n is None else f'{out_file}_{n}.gv'
    graph.render(directory=f'{out_file}_export', filename=filename)


def read_csv(filename, n_classes):
    """Read CSV dataset from file."""
    X = []
    Y = []
    with open(filename) as csv_file:
        csv_data = csv.reader(csv_file, delimiter=';')
        intestation = next(csv_data)
        feat_names = intestation[:-n_classes]
        class_names = intestation[-n_classes:]
        for row in csv_data:
            X.append(row[:-n_classes])
            Y.append(row[-n_classes:])
    return X, Y, feat_names, class_names


def write_csv(data, feat_names, class_names, filename):
    """Write CSV dataset to file."""
    with open(filename, 'w') as csv_file:
        csv_writer = csv.writer(csv_file)
        csv_writer.writerow(feat_names + class_names)
        csv_writer.writerows(data)


if __name__ == '__main__':
    main(obj={})
